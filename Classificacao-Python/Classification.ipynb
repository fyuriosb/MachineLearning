{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Autor: Valkson Saraiva\n",
    "\n",
    "# Fonte para Download do Dataset: https://www.openml.org/d/31\n",
    "\n",
    "# Descrição dos dados: \n",
    "# Este conjunto de dados classifica as pessoas descritas por um conjunto de atributos como riscos de crédito bons ou ruins.\n",
    "\n",
    "# Algoritmo de Classificação: Random Forest Classifier\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/dataset_31_credit-g.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    700\n",
       "0    300\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforma classes em 0 ou 1 e verifica balanceamento\n",
    "class_le = preprocessing.LabelEncoder()\n",
    "data[\"class\"] = class_le.fit_transform(data['class'])\n",
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    700\n",
       "0    700\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Faz o balanceamento das classes, pois tinham 700 registros em uma e apenas 300 na outra.\n",
    "# O melhor resultado foi alcançado replicando os dados da classe minoritária até chegar aos 700 da classe majoritária\n",
    "df_majority = data[data[\"class\"]==1]\n",
    "df_minority = data[data[\"class\"]==0]\n",
    "\n",
    "# Replicando os dados da classe minoritária até chegar aos 700 da classe majoritária\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=700,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "data = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Reduzindo a classe majoritária aos 300 da classe minoritária\n",
    "#df_majority_downsampled = resample(df_majority, \n",
    "#                                 replace=False,    # sample without replacement\n",
    "#                                 n_samples=300,     # to match minority class\n",
    "#                                 random_state=123) # reproducible results\n",
    "#data = pd.concat([df_minority, df_majority_downsampled])\n",
    " \n",
    "# Exibindo as quantidades de registros de cada classe\n",
    "data[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transformando dados categóricos em novas colunas(features) com 0 ou 1\n",
    "# Alterando os valores para número, para o nome das features não ficarem muito extensos.\n",
    "# Incluindo o prefixo das colunas com o nome original da feature\n",
    "\n",
    "#data[\"checking_status\"].unique()\n",
    "checking_status_mapper = {'\\'no checking\\'':1,\n",
    "                '\\'<0\\'':2, \n",
    "                '\\'0<=X<200\\'':3,\n",
    "                '\\'>=200\\'':4}\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data['checking_status'].replace(checking_status_mapper),prefix='checking_status')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#Reescalando dados numéricos\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "duration_scale = minmax_scale.fit_transform(data[\"duration\"].values.reshape(-1,1))\n",
    "data[\"duration\"] = duration_scale\n",
    "\n",
    "age_scale = minmax_scale.fit_transform(data[\"age\"].values.reshape(-1,1))\n",
    "data[\"age\"] = age_scale\n",
    "\n",
    "credit_amount_scale = minmax_scale.fit_transform(data[\"credit_amount\"].values.reshape(-1,1))\n",
    "data[\"credit_amount\"] = credit_amount_scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transformando dados categóricos em novas colunas(features) com 0 ou 1\n",
    "# Alterando os valores para número, para o nome das features não ficarem muito extensos.\n",
    "# Incluindo o prefixo das colunas com o nome original da feature\n",
    "\n",
    "#data[\"credit_history\"].unique()\n",
    "credit_history_mapper = {\n",
    "                '\\'critical/other existing credit\\'':1,\n",
    "                '\\'existing paid\\'':2, \n",
    "                '\\'delayed previously\\'':3,\n",
    "                '\\'no credits/all paid\\'':4,\n",
    "                '\\'all paid\\'':5}\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data['credit_history'].replace(credit_history_mapper),prefix='credit_history')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transformando dados categóricos em novas colunas(features) com 0 ou 1\n",
    "# Alterando os valores para número, para o nome das features não ficarem muito extensos.\n",
    "# Incluindo o prefixo das colunas com o nome original da feature\n",
    "\n",
    "#data[\"purpose\"].unique()\n",
    "purpose_mapper = {\n",
    "                'radio/tv':1,\n",
    "                'education':2, \n",
    "                'furniture/equipment':3,\n",
    "                '\\'new car\\'':4,\n",
    "                '\\'used car\\'':5,\n",
    "                'business':6,\n",
    "                '\\'domestic appliance\\'':7,\n",
    "                'repairs':8,\n",
    "                'other':9,\n",
    "                'retraining':10}\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data['purpose'].replace(purpose_mapper),prefix='purpose')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transformando dados categóricos em novas colunas(features) com 0 ou 1\n",
    "# Alterando os valores para número, para o nome das features não ficarem muito extensos.\n",
    "# Incluindo o prefixo das colunas com o nome original da feature\n",
    "\n",
    "#data[\"savings_status\"].unique()\n",
    "savings_status_mapper = {\n",
    "                '\\'no known savings\\'':1,\n",
    "                '\\'<100\\'':2, \n",
    "                '\\'100<=X<500\\'':3,\n",
    "                '\\'500<=X<1000\\'':4,\n",
    "                '\\'>=1000\\'':5}\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data['savings_status'].replace(savings_status_mapper),prefix='savings_status')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transformando dados categóricos em novas colunas(features) com 0 ou 1\n",
    "# Alterando os valores para número, para o nome das features não ficarem muito extensos.\n",
    "# Incluindo o prefixo das colunas com o nome original da feature\n",
    "\n",
    "#data[\"employment\"].unique()\n",
    "employment_mapper = {\n",
    "                'unemployed':1,\n",
    "                '\\'<1\\'':2, \n",
    "                '\\'1<=X<4\\'':3,\n",
    "                '\\'4<=X<7\\'':4,\n",
    "                '\\'>=7\\'':5}\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data['employment'].replace(employment_mapper),prefix='employment')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transformando dados categóricos em novas colunas(features) com 0 ou 1\n",
    "# Alterando os valores para número, para o nome das features não ficarem muito extensos.\n",
    "# Incluindo o prefixo das colunas com o nome original da feature\n",
    "\n",
    "#data[\"personal_status\"].unique()\n",
    "personal_status_mapper = {\n",
    "                '\\'male single\\'':1,\n",
    "                '\\'female div/dep/mar\\'':2, \n",
    "                '\\'male div/sep\\'':3,\n",
    "                '\\'male mar/wid\\'':4}\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data['personal_status'].replace(personal_status_mapper),prefix='personal_status')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transformando dados categóricos em novas colunas(features) com 0 ou 1\n",
    "# Alterando os valores para número, para o nome das features não ficarem muito extensos.\n",
    "# Incluindo o prefixo das colunas com o nome original da feature\n",
    "\n",
    "#data[\"other_parties\"].unique()\n",
    "other_parties_mapper = {\n",
    "                'none':1,\n",
    "                'guarantor':2, \n",
    "                '\\'co applicant\\'':3}\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data['other_parties'].replace(other_parties_mapper),prefix='other_parties')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transformando dados categóricos em novas colunas(features) com 0 ou 1\n",
    "# Alterando os valores para número, para o nome das features não ficarem muito extensos.\n",
    "# Incluindo o prefixo das colunas com o nome original da feature\n",
    "\n",
    "#data[\"property_magnitude\"].unique()\n",
    "property_magnitude_mapper = {\n",
    "                '\\'real estate\\'':1,\n",
    "                '\\'life insurance\\'':2, \n",
    "                '\\'no known property\\'':3,\n",
    "                'car':4}\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data['property_magnitude'].replace(property_magnitude_mapper),prefix='property_magnitude')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transformando dados categóricos em novas colunas(features) com 0 ou 1\n",
    "# Alterando os valores para número, para o nome das features não ficarem muito extensos.\n",
    "# Incluindo o prefixo das colunas com o nome original da feature\n",
    "\n",
    "#data[\"other_payment_plans\"].unique()\n",
    "other_payment_plans_mapper = {\n",
    "                'none':1,\n",
    "                'bank':2, \n",
    "                'stores':3}\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data['other_payment_plans'].replace(other_payment_plans_mapper),prefix='other_payment_plans')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transformando dados categóricos em novas colunas(features) com 0 ou 1\n",
    "# Alterando os valores para número, para o nome das features não ficarem muito extensos.\n",
    "# Incluindo o prefixo das colunas com o nome original da feature\n",
    "\n",
    "#data[\"housing\"].unique()\n",
    "housing_mapper = {\n",
    "                'own':1,\n",
    "                '\\'for free\\'':2, \n",
    "                'rent':3}\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data['housing'].replace(housing_mapper),prefix='housing')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transformando dados categóricos em novas colunas(features) com 0 ou 1\n",
    "# Alterando os valores para número, para o nome das features não ficarem muito extensos.\n",
    "# Incluindo o prefixo das colunas com o nome original da feature\n",
    "\n",
    "#data[\"job\"].unique()\n",
    "job_mapper = {\n",
    "                'skilled':1,\n",
    "                '\\'unskilled resident\\'':2, \n",
    "                '\\'high qualif/self emp/mgmt\\'':3, \n",
    "                '\\'unemp/unskilled non res\\'':4}\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data['job'].replace(job_mapper),prefix='job')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transformando os valores em 0 ou 1\n",
    "own_telephone_le = preprocessing.LabelEncoder()\n",
    "data[\"own_telephone\"] = own_telephone_le.fit_transform(data['own_telephone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transformando os valores em 0 ou 1\n",
    "foreign_worker_le = preprocessing.LabelEncoder()\n",
    "data[\"foreign_worker\"] = foreign_worker_le.fit_transform(data['foreign_worker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Criando vetor para filtrar as features selecionadas para treinar o modelo\n",
    "features = ['checking_status_1', 'checking_status_2','checking_status_3','checking_status_4','duration',\n",
    "            'credit_history_1','credit_history_2','credit_history_3', 'credit_history_4','credit_history_5',\n",
    "            'purpose_1','purpose_2','purpose_3','purpose_4','purpose_5','purpose_6','purpose_7','purpose_8','purpose_9',\n",
    "            'purpose_10','credit_amount','savings_status_1','savings_status_2','savings_status_3','savings_status_4',\n",
    "            'savings_status_5','employment_1','employment_2','employment_3','employment_4','employment_5',\n",
    "            'installment_commitment','personal_status_1','personal_status_2' ,'personal_status_3' ,'personal_status_4',\n",
    "            'other_parties_1','other_parties_2','other_parties_3','residence_since',\n",
    "            'property_magnitude_1','property_magnitude_2','property_magnitude_3','property_magnitude_4',\n",
    "            'age','other_payment_plans_1','other_payment_plans_2','other_payment_plans_3','housing_1','housing_2','housing_3',\n",
    "            'existing_credits','job_1','job_2','job_3','job_4','num_dependents','own_telephone','foreign_worker'\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separando os dados de treinamento e teste do modelo. 30% para teste.\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data[\"class\"], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('checking_status_1', 0.062122061567868286)\n",
      "('checking_status_2', 0.038024977033000042)\n",
      "('checking_status_3', 0.015708140730398751)\n",
      "('checking_status_4', 0.0085763691989088914)\n",
      "('duration', 0.075815079450171588)\n",
      "('credit_history_1', 0.025170614409581946)\n",
      "('credit_history_2', 0.012992843690814763)\n",
      "('credit_history_3', 0.0085389627856566012)\n",
      "('credit_history_4', 0.012116276094129011)\n",
      "('credit_history_5', 0.0078592507655325678)\n",
      "('purpose_1', 0.012722074782807086)\n",
      "('purpose_2', 0.0080030694949578558)\n",
      "('purpose_3', 0.015053354540754753)\n",
      "('purpose_4', 0.013768777244989573)\n",
      "('purpose_5', 0.0094131952453632862)\n",
      "('purpose_6', 0.0075910499321156944)\n",
      "('purpose_7', 0.0020678379928174705)\n",
      "('purpose_8', 0.0064200102936834598)\n",
      "('purpose_9', 0.0014025689034887574)\n",
      "('purpose_10', 0.00096670277499794522)\n",
      "('credit_amount', 0.097815050125862266)\n",
      "('savings_status_1', 0.014149038953822704)\n",
      "('savings_status_2', 0.021373751343754979)\n",
      "('savings_status_3', 0.0081396359877101473)\n",
      "('savings_status_4', 0.0056363245817385521)\n",
      "('savings_status_5', 0.0075570318259140096)\n",
      "('employment_1', 0.0069211601440572279)\n",
      "('employment_2', 0.013441958438969051)\n",
      "('employment_3', 0.014976532715552269)\n",
      "('employment_4', 0.014530977771904728)\n",
      "('employment_5', 0.013564650450593506)\n",
      "('installment_commitment', 0.036326598237546796)\n",
      "('personal_status_1', 0.01583371373132085)\n",
      "('personal_status_2', 0.015387612250508571)\n",
      "('personal_status_3', 0.0078074583184730654)\n",
      "('personal_status_4', 0.0083774421113538416)\n",
      "('other_parties_1', 0.009798638691700088)\n",
      "('other_parties_2', 0.0087032249655325921)\n",
      "('other_parties_3', 0.0065922185797555087)\n",
      "('residence_since', 0.031773919802815735)\n",
      "('property_magnitude_1', 0.015246074556132456)\n",
      "('property_magnitude_2', 0.01374195015934019)\n",
      "('property_magnitude_3', 0.010018126264131472)\n",
      "('property_magnitude_4', 0.013135462449883459)\n",
      "('age', 0.082474575126627633)\n",
      "('other_payment_plans_1', 0.01829121359199324)\n",
      "('other_payment_plans_2', 0.012718070977519742)\n",
      "('other_payment_plans_3', 0.0092774712672430842)\n",
      "('housing_1', 0.01307375157427417)\n",
      "('housing_2', 0.0077181409700805195)\n",
      "('housing_3', 0.0093005144921738704)\n",
      "('existing_credits', 0.018233671625765377)\n",
      "('job_1', 0.01421106463836771)\n",
      "('job_2', 0.01103104932731864)\n",
      "('job_3', 0.013928834897614092)\n",
      "('job_4', 0.0022240423160193026)\n",
      "('num_dependents', 0.011907214003401402)\n",
      "('own_telephone', 0.015445823233712838)\n",
      "('foreign_worker', 0.0049827925674761726)\n"
     ]
    }
   ],
   "source": [
    "# Criando a instância do random forest classifier para identificar quais features mais representam os dados\n",
    "clf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the name and gini importance of each feature\n",
    "for feature in zip(features, clf.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10000, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False),\n",
       "        norm_order=1, prefit=False, threshold=0.03)"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando um seletor para filtrar apenas as features cuja representatividade é superior a 0.03\n",
    "# Testei incluindo features com menor representatividade mas não obtive um resultado melhor\n",
    "sfm = SelectFromModel(clf, threshold=0.03)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking_status_1\n",
      "checking_status_2\n",
      "duration\n",
      "credit_amount\n",
      "installment_commitment\n",
      "residence_since\n",
      "age\n"
     ]
    }
   ],
   "source": [
    "# Listando as features filtradas\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(features[feature_list_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Criando novos datasets contendo apenas as features selecionadas\n",
    "X_important_train = sfm.transform(X_train)\n",
    "X_important_test = sfm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10000, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando nova instância do random forest classifier e treinando-o apenas com as features selecionadas\n",
    "clf_important = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "\n",
    "# Treinando-o apenas com as features selecionadas\n",
    "clf_important.fit(X_important_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91190476190476188"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando os dados de teste para o modelo predizer a classificação\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Visualizando a acurácia do Modelo\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito    0    1  All\n",
      "Real                  \n",
      "0        197   16  213\n",
      "1         21  186  207\n",
      "All      218  202  420\n"
     ]
    }
   ],
   "source": [
    "# Matriz de confusão - Visualizando se o modelo realmente acertou a marioria das classes, tanto positivas quanto negativas.\n",
    "print(pd.crosstab(y_test,y_pred,rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
